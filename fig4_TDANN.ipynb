{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import label, sum as ndi_sum\n",
    "import matplotlib.image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize TDANN41 image preference map\n",
    "image = Image.open(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_IT.bmp\")\n",
    "width, height = image.size\n",
    "resized_image = image.resize((int(np.round(width/16)), int(np.round(height/16))), Image.Resampling.LANCZOS)\n",
    "resized_image.save(\"/Users/dunhan/Desktop/topoV4/som/Figures/TDANN41.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDANN map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare TDANN later layer responses to 50K images\n",
    "file_names_all = ['1_5kfeatures.npz', '2_5kfeatures.npz', '3_5kfeatures.npz', '4_5kfeatures.npz', \n",
    "                '5_5kfeatures.npz', '6_5kfeatures.npz', '7_5kfeatures.npz', '8_5kfeatures.npz', \n",
    "                '9_5kfeatures.npz', '10_5kfeatures.npz']\n",
    "feature_folder_path = '/Volumes/dunhanSSD/topoV4/' # the path to the folder of pre-computed responses\n",
    "data = np.zeros((1, 50176))\n",
    "for file_name in tqdm(range(len(file_names_all)), desc=\"10 files to go\", disable=False): # iterate through all the files\n",
    "    features = np.load(feature_folder_path + file_names_all[file_name])[\"layer30\"] # targeted at V4, of shape (5000, 256, 14, 14)\n",
    "    features = features.reshape(features.shape[0], -1) # of shape (5000, n_units)\n",
    "    data = np.concatenate((data, features), axis=0) # of shape(50K_images, n_units)\n",
    "data = data[1:, :] # remove the first row of zeros, of shape (50000, 50176)\n",
    "print(data.shape)\n",
    "np.save(\"/Volumes/dunhanSSD/topoV4/TDANN31_V2.npy\", data) # save the data\n",
    "del data, features # release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of TDANN final network & positions, into a 2D 60 by 60 gridded map\n",
    "# combined_features = np.load(\"/Volumes/dunhanSSD/topoV4/TDANN_final/responses/TDANN31_V4.npy\") # (50000, 50176)\n",
    "combined_features = np.load(\"/Volumes/dunhanSSD/topoV4/TDANN_final/responses/layer41.npy\") # (50000, 25088)\n",
    "positions = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANNfinal_positions/layer4.1.npz\")[\"coordinates\"] # (25088, 2)\n",
    "folder_path = \"/Users/dunhan/Desktop/topoV4/50K_Imgset/\"\n",
    "cortical_size = max(positions[:, 0]) - min(positions[:, 0]) # define the length of the 2D plane\n",
    "grid_num = 60 # each grid contains the most-preferred 9 images by the mean within-grid-units' response\n",
    "grids_count = int(grid_num ** 2)\n",
    "num_imgs_each_side = 3 # number of images on each side of the grid, total number of images in a grid should be squared\n",
    "# define the size of a single image\n",
    "img_size = 30\n",
    "line_width = 5\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width, \n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "# To store each grid's agregated response to all 50K images, with an additional roi\n",
    "TDANN41_weight = np.zeros((grid_num, grid_num, 50000))\n",
    "roi = np.zeros((grid_num, grid_num))\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\"):\n",
    "    for j in range(grid_num):\n",
    "        # first find all units in this current grid\n",
    "        xmin_cortex = cortical_size / grid_num * i\n",
    "        xmax_cortex = cortical_size / grid_num * (i + 1)\n",
    "        ymin_cortex = cortical_size / grid_num * j\n",
    "        ymax_cortex = cortical_size / grid_num * (j + 1)\n",
    "        # find all units in this current grid\n",
    "        units_within_grid_indeices = np.where((positions[:, 0] >= xmin_cortex) & (positions[:, 0] < xmax_cortex) & (positions[:, 1] >= ymin_cortex) & (positions[:, 1] < ymax_cortex))[0]\n",
    "        if len(units_within_grid_indeices) > 0:\n",
    "            roi[i, j] = 1\n",
    "            # compute the mean response of all units (neurons) within this grid to all 50K images (into a row vector)\n",
    "            mean_responses = np.mean(combined_features[:, units_within_grid_indeices], axis=1).T\n",
    "            TDANN41_weight[i, j, :] = mean_responses\n",
    "            image_label = np.arange(50000) + 1 # 1-indexed image names\n",
    "            # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "            mean_responses, image_label = zip(*sorted(zip(mean_responses,image_label)))\n",
    "            image_label = np.flip(image_label[-int(num_imgs_each_side ** 2):]) # take the top nine images with largest mean response\n",
    "\n",
    "            # locate the top left corner of the current grid in the map\n",
    "            x = i * (img_size*3 + line_width) + line_width\n",
    "            y = j * (img_size*3 + line_width) + line_width\n",
    "            \n",
    "            # fill the map's current grid with the selected nine images\n",
    "            for row in range(3):\n",
    "                for col in range(3):\n",
    "                    # load the image\n",
    "                    path = folder_path + str(int(image_label[row*3+col])) + \".bmp\" # the image name is 1-indexed\n",
    "                    img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                    img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "                    # put the image onto the map\n",
    "                    # if i > 10 and i < 50 and j > 15 and j < 50:\n",
    "                    # img_label.append(image_label[row*3+col])\n",
    "                    map[x + row * img_size : x + (row + 1) * img_size, \n",
    "                        y + col * img_size : y + (col + 1) * img_size, \n",
    "                        :] = img\n",
    "        else: # white out the grid if no units are in this grid\n",
    "            x = i * (img_size*3 + line_width)\n",
    "            y = j * (img_size*3 + line_width)\n",
    "            map[x : x + img_size*3 + line_width*2, \n",
    "                y : y + img_size*3 + line_width*2, \n",
    "                :] = 1.0\n",
    "\n",
    "matplotlib.image.imsave('/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_IT.bmp', map)\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_weight.npy\", TDANN41_weight)\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_roi.npy\", roi)\n",
    "del map\n",
    "\n",
    "# save the top-k most preferred images for each TDANN41 unitn in 0-indexed format\n",
    "print(combined_features.shape)\n",
    "imgs_0index = np.zeros((combined_features.shape[1], 1000))\n",
    "for i in tqdm(range(combined_features.shape[1])):\n",
    "    image_label = np.arange(50000) # 0-indexed image\n",
    "    response_vector, image_label = zip(*sorted(zip(combined_features[:, i], image_label), reverse=True)) # sort from large to small\n",
    "    imgs_0index[i, :] = image_label[:1000] # store the 0-indexed top 1000 images for each unit\n",
    "print(imgs_0index.shape)\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/ResNet/responses/TDANN41rsp_1kimgs_0index.npy\", imgs_0index)\n",
    "del combined_features, positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning curve half at the top images: 1205.8199259508583 1884.0477172733094\n",
      "pearson correlation of tuning curve between V4 and TDANN41: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/sxy3f69j5_s5tn7m8cxwrgvw0000gn/T/ipykernel_57551/2783818924.py:102: RuntimeWarning: invalid value encountered in divide\n",
      "  mean_std_rois[:, 0] /= mean_std_rois[:, 2] # average mean\n",
      "/var/folders/4j/sxy3f69j5_s5tn7m8cxwrgvw0000gn/T/ipykernel_57551/2783818924.py:103: RuntimeWarning: invalid value encountered in divide\n",
      "  mean_std_rois[:, 1] /= mean_std_rois[:, 2] # average std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation of cordis function between V4 and TDANN41: 0.778\n"
     ]
    }
   ],
   "source": [
    "# tuning curve comparison figure\n",
    "# Compare the tuning curves of V4 digital twin benchmark and the learned SOM\n",
    "layer = \"layer41\"\n",
    "roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "response = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/Prsp.npy\")\n",
    "v4_benchmark = response[:, roi == 1] # (50000, 128, 128) into (50000, 3048)\n",
    "v4_benchmark = np.sort(v4_benchmark, axis=0)[::-1]  # Sort each column along rows (flip for descending order)\n",
    "v4_mean = np.mean(v4_benchmark, axis=1) # mean tuning curve\n",
    "v4_std = np.std(v4_benchmark, axis=1) # tuning curve std\n",
    "if layer == \"layer31\":\n",
    "    rsp = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_weight.npy\")\n",
    "    roi = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_roi.npy\")\n",
    "elif layer == \"layer41\":\n",
    "    rsp = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_weight.npy\")\n",
    "    roi = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_roi.npy\")\n",
    "rsp = rsp[np.where(roi == 1)[0], np.where(roi == 1)[1], :] # (3277, 50000)\n",
    "rsp = np.sort(rsp.T, axis=0)[::-1]  # Sort each column along rows (flip for descending order), (50000, 3277)\n",
    "rsp_mean = np.mean(rsp, axis=1) # mean tuning curve\n",
    "rsp_std = np.std(rsp, axis=1) # tuning curve std\n",
    "\n",
    "# normalize every tuning curve\n",
    "index = []\n",
    "for i in range(rsp.shape[1]):\n",
    "    assert len(rsp[:, i]) == 50000\n",
    "    half = (np.max(rsp[:, i]) - np.min(rsp[:, i])) / 2\n",
    "    for j in range(50000):\n",
    "        if rsp[j, i] <= half:\n",
    "            index.append(j)\n",
    "            break\n",
    "print(\"Tuning curve half at the top images:\", np.mean(index), np.std(index))\n",
    "if layer == \"layer31\":\n",
    "    print(\"pearson correlation of tuning curve between V4 and TDANN31: {:.3f}\".format(pearsonr(np.concatenate((v4_mean, v4_std)), np.concatenate((rsp_mean, rsp_std)))[0]))\n",
    "elif layer == \"layer41\":\n",
    "    print(\"pearson correlation of tuning curve between V4 and TDANN41: {:.3f}\".format(pearsonr(np.concatenate((v4_mean, v4_std)), np.concatenate((rsp_mean, rsp_std)))[0]))\n",
    "\n",
    "# pairwise grid tuning curve coorelation as a function of exactly the map physical distance between them\n",
    "def cordis(rsp):\n",
    "    # check input response\n",
    "    if rsp.shape[1] == rsp.shape[2] == 128: # (50000, 128, 128) V4 benchmark\n",
    "        roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # (128, 128)\n",
    "    else: roi = np.ones((60, 60)).astype(int) # artificial som map weight response\n",
    "    size = roi.shape[0]\n",
    "    assert size == roi.shape[1]\n",
    "    num_roi = int(np.sum(roi))\n",
    "    # response, roi data preparation\n",
    "    response = np.zeros((num_roi, 50000))\n",
    "    position = np.zeros((num_roi, 2))\n",
    "    voxel_index = 0\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if roi[i, j] == 1:\n",
    "                response[voxel_index, :] = rsp[:, i, j]\n",
    "                position[voxel_index, 0] = i\n",
    "                position[voxel_index, 1] = j\n",
    "                voxel_index += 1\n",
    "    assert voxel_index == num_roi\n",
    "    # calculate the correlation matrix\n",
    "    cordis_matrix = np.zeros((num_roi, num_roi, 2)) # 0th entry for correlation, 1st entry for pairwise map distance\n",
    "    for i in tqdm(range(num_roi), desc=\"calculating correlation matrix...\", disable=False):\n",
    "        for j in range(i, num_roi):\n",
    "            # correlation calculation\n",
    "            if i != j:\n",
    "                cordis_matrix[i, j, 0] = pearsonr(response[i, :], response[j, :])[0]\n",
    "                cordis_matrix[j, i, 0] = cordis_matrix[i, j, 0]\n",
    "            else: cordis_matrix[i, j, 0] = 1.0\n",
    "            # distance calculation\n",
    "            cordis_matrix[i, j, 1] = np.sqrt((position[i, 0] - position[j, 0]) ** 2 + (position[i, 1] - position[j, 1]) ** 2)\n",
    "            cordis_matrix[j, i, 1] = cordis_matrix[i, j, 1]\n",
    "    return cordis_matrix\n",
    "\n",
    "def cordis_avg(cordis_matrix, segment_num=100):\n",
    "    num_roi = cordis_matrix.shape[0]\n",
    "    assert num_roi == cordis_matrix.shape[1]\n",
    "    pd = cordis_matrix[:, :, 1] # distance (3048, 3048)\n",
    "    pc = cordis_matrix[:, :, 0] # correlation (3048, 3048)\n",
    "    dismax = np.max(pd) # maximum distance\n",
    "    dismin = np.min(pd) # minimum distance\n",
    "    segment_len = (dismax - dismin) / segment_num # length of one single segment\n",
    "    segments = np.zeros((num_roi, segment_num, 2)) # store the mean correlation and standard deviation of all correlation estimates within all samples of each segment\n",
    "    for i in tqdm(range(num_roi), desc=\"sorting...\", disable=True):\n",
    "        sorted_indices = np.argsort(pd[i, :]) # sort the distance from smallest to largest, get its indices\n",
    "        pd[i, :] = pd[i, sorted_indices] # distance matrix row vector sorted, from smallest to largest\n",
    "        pc[i, :] = pc[i, sorted_indices] # correlation matrix row vector sorted, from smallest to largest\n",
    "        for s in range(segment_num):\n",
    "            # indices of all entries within the current pairwise distance segment\n",
    "            segment_indices = np.where((pd[i, :] >= dismin + s * segment_len) & (pd[i, :] < dismin + (s + 1) * segment_len))[0]\n",
    "            if len(segment_indices) > 0:\n",
    "                selected_cor = pc[i, segment_indices] # current segment samples' correlation estimates\n",
    "                segments[i, s, 0] = np.mean(selected_cor) # average\n",
    "                segments[i, s, 1] = np.std(selected_cor) # standard deviation\n",
    "            else:\n",
    "                segments[i, s, 0] = -1\n",
    "                segments[i, s, 1] = -1\n",
    "    # compute the average of all ROIs' correlation estimates (mean and std) within each segment\n",
    "    mean_std_rois = np.zeros((segment_num, 3))\n",
    "    for i in range(num_roi):\n",
    "        for s in range(segment_num):\n",
    "            if segments[i, s, 0] != -1 and segments[i, s, 1] != -1:\n",
    "                mean_std_rois[s, 0] += segments[i, s, 0] # mean\n",
    "                mean_std_rois[s, 1] += segments[i, s, 1] # std\n",
    "                mean_std_rois[s, 2] += 1 # count\n",
    "    mean_std_rois[:, 0] /= mean_std_rois[:, 2] # average mean\n",
    "    mean_std_rois[:, 1] /= mean_std_rois[:, 2] # average std\n",
    "    mean_std_rois = mean_std_rois[:, :2] # discard the count\n",
    "    return mean_std_rois\n",
    "\n",
    "# V4 digital twin as benchmark\n",
    "segment_num = 100\n",
    "cordis_v4 = np.load(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/cordis_v4_benchmark.npy\")\n",
    "mean_std_rois = cordis_avg(cordis_v4, segment_num) # V4 benchmark\n",
    "if layer == \"layer31\":\n",
    "    cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/cordis_TDANN31.npy\")\n",
    "elif layer == \"layer41\":\n",
    "    cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/cordis_TDANN41.npy\")\n",
    "cordis_rsom[np.isinf(cordis_rsom) | np.isnan(cordis_rsom)] = 0\n",
    "cordis_rsom = np.nan_to_num(cordis_rsom, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "mean_std_rois_rsom = cordis_avg(cordis_rsom, segment_num)\n",
    "mean_std_rois_rsom = np.nan_to_num(mean_std_rois_rsom, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "# visualization, as a comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(3, 6))\n",
    "axes[0].plot(rsp_mean, color='gray')\n",
    "axes[0].fill_between(range(len(rsp_mean)), rsp_mean - rsp_std, rsp_mean + rsp_std, color='gray', alpha=0.3)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_xlabel('50K imgs', fontsize=18)\n",
    "axes[0].set_ylabel('response', fontsize=18)\n",
    "axes[0].set_title(\"Tuning curve\", fontsize=22)\n",
    "axes[1].plot(mean_std_rois_rsom[:, 0], color='gray')\n",
    "axes[1].fill_between(np.arange((len(mean_std_rois_rsom[:, 0]))), mean_std_rois_rsom[:, 0]-mean_std_rois_rsom[:, 1], mean_std_rois_rsom[:, 0]+mean_std_rois_rsom[:, 1], color='gray', alpha=0.3)\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "axes[1].set_xlabel('Pairwise distance', fontsize=18)\n",
    "axes[1].set_ylabel('Tuning correlation', fontsize=18)\n",
    "# axes[1].set_title(\"Correlation and distance\", fontsize=22)\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "if layer == \"layer31\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_tuning.png\", dpi=1000)\n",
    "    print(\"pearson correlation of cordis function between V4 and TDANN31: {:.3f}\".format(pearsonr(np.concatenate((mean_std_rois[:, 0], mean_std_rois[:, 1])), \n",
    "                                                                                                np.concatenate((mean_std_rois_rsom[:, 0], mean_std_rois_rsom[:, 1])))[0]))\n",
    "elif layer == \"layer41\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_tuning.png\", dpi=1000)\n",
    "    print(\"pearson correlation of cordis function between V4 and TDANN41: {:.3f}\".format(pearsonr(np.concatenate((mean_std_rois[:, 0], mean_std_rois[:, 1])), \n",
    "                                                                                                np.concatenate((mean_std_rois_rsom[:, 0], mean_std_rois_rsom[:, 1])))[0]))\n",
    "plt.close()\n",
    "\n",
    "# TDANN31, purpoted V4 layer\n",
    "# Tuning curve half at the top images: 20475.135222150675 16965.060078655137\n",
    "# pearson correlation of tuning curve between V4 and TDANN31: 0.708\n",
    "# pearson correlation of cordis function between V4 and TDANN31: 0.838\n",
    "\n",
    "# TDANN41, purpoted IT layer\n",
    "# Tuning curve half at the top images: 1205.8199259508583 1884.0477172733094\n",
    "# pearson correlation of tuning curve between V4 and TDANN41: 0.947\n",
    "# pearson correlation of cordis function between V4 and TDANN41: 0.778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = np.load(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/rsptop_0index.npy\")\n",
    "roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T\n",
    "img0 = img0[np.where(roi == 1)[0], np.where(roi == 1)[1], :].flatten() # (3048*9,)\n",
    "img0 = np.unique(img0).astype(int) # 0index of unique top-9 images preferred by 3048 V4 neuronal columns\n",
    "img_num = len(img0)\n",
    "\n",
    "# Load the V4 digital twin responses to 50k images\n",
    "response = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/Prsp.npy\") # of shape (50000, 128, 128)\n",
    "rsp = np.zeros((3048, 50000))\n",
    "index = 0\n",
    "for i in range(128):\n",
    "    for j in range(128):\n",
    "        if roi[i, j] == 1:\n",
    "            rsp[index, :] = response[:, i, j]\n",
    "            index += 1\n",
    "del response\n",
    "\n",
    "rsm_V4 = np.zeros((img_num, img_num))\n",
    "for i in tqdm(range(img_num), desc=\"V4 RSM calculation...\", disable=False):\n",
    "    for j in range(i, img_num):  # Start j from i to only compute the upper triangular\n",
    "        rsm_V4[i, j] = np.corrcoef(rsp[:, img0[i]], rsp[:, img0[j]])[0, 1]\n",
    "        rsm_V4[j, i] = rsm_V4[i, j]  # Mirror the value to the lower triangular part\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/rsm_V4.npy\", rsm_V4)\n",
    "del rsp\n",
    "\n",
    "rsp = np.load(\"/Volumes/dunhanSSD/topoV4/TDANN_final/responses/TDANN31_V4.npy\").T # to shape (50176, 50000)\n",
    "assert rsp.shape[1] == 50000\n",
    "rsm_TDANN31 = np.zeros((img_num, img_num))\n",
    "for i in tqdm(range(img_num), desc=\"TDANN31 RSM calculation...\", disable=False):\n",
    "    for j in range(i, img_num):  # Start j from i to only compute the upper triangular\n",
    "        rsm_TDANN31[i, j] = np.corrcoef(rsp[:, img0[i]], rsp[:, img0[j]])[0, 1]\n",
    "        rsm_TDANN31[j, i] = rsm_TDANN31[i, j]  # Mirror the value to the lower triangular part\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/rsm_TDANN31.npy\", rsm_TDANN31)\n",
    "del rsp\n",
    "\n",
    "rsp = np.load(\"/Volumes/dunhanSSD/topoV4/TDANN_final/responses/layer41.npy\").T # to shape (25088, 50000)\n",
    "assert rsp.shape[1] == 50000\n",
    "rsm_TDANN41 = np.zeros((img_num, img_num))\n",
    "for i in tqdm(range(img_num), desc=\"TDANN31 RSM calculation...\", disable=False):\n",
    "    for j in range(i, img_num):  # Start j from i to only compute the upper triangular\n",
    "        rsm_TDANN41[i, j] = np.corrcoef(rsp[:, img0[i]], rsp[:, img0[j]])[0, 1]\n",
    "        rsm_TDANN41[j, i] = rsm_TDANN41[i, j]  # Mirror the value to the lower triangular part\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/rsm_TDANN41.npy\", rsm_TDANN41)\n",
    "del rsp\n",
    "\n",
    "V4_TDANN31 = np.corrcoef(rsm_V4.flatten(), rsm_TDANN31.flatten())[0, 1]\n",
    "print(\"V4_TDANN31:\", V4_TDANN31) # 0.30309409089513717\n",
    "V4_TDANN41 = np.corrcoef(rsm_V4.flatten(), rsm_TDANN41.flatten())[0, 1]\n",
    "print(\"V4_TDANN41:\", V4_TDANN41) # 0.24174864985821207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinotopy map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = \"layer31\"\n",
    "if layer == \"layer41\":\n",
    "    positions = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANNfinal_positions/layer4.1.npz\")[\"coordinates\"] # (25088, 2)\n",
    "elif layer == \"layer31\":\n",
    "    positions = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANNfinal_positions/layer3.1.npz\")[\"coordinates\"] # (50176, 2)\n",
    "polar_angle = np.zeros((positions.shape[0])) # theta\n",
    "eccentricity = np.zeros((positions.shape[0])) # r\n",
    "for i in range(positions.shape[0]):\n",
    "    if layer == \"layer41\": # 25088 = 512 * 7 * 7\n",
    "        depth_index = i // (7 * 7)        # Get index along the first dimension (512)\n",
    "        row_col_index = i % (7 * 7)       # Remaining index within the 7x7 matrix\n",
    "        row_index = row_col_index // 7    # Get index along the second dimension (7)\n",
    "        col_index = row_col_index % 7     # Get index along the third dimension (7)\n",
    "        polar_angle[i] = math.degrees(np.arctan2((col_index-3), (row_index-3)))\n",
    "        eccentricity[i] = math.degrees(math.atan(np.sqrt((row_index-3) ** 2 + (col_index-3) ** 2) / 45)) # assuming 45 cm away from the fovea\n",
    "    elif layer == \"layer31\": # 50176 = 256 * 14 * 14\n",
    "        depth_index = i // (14 * 14)\n",
    "        row_col_index = i % (14 * 14)\n",
    "        row_index = row_col_index // 14\n",
    "        col_index = row_col_index % 14\n",
    "        polar_angle[i] = math.degrees(np.arctan2((col_index-7), (row_index-7)))\n",
    "        eccentricity[i] = math.degrees(math.atan(np.sqrt((row_index-7) ** 2 + (col_index-7) ** 2) / 45)) # assuming 45 cm away from the fovea\n",
    "polar_angle = (polar_angle - np.min(polar_angle)) / (np.max(polar_angle) - np.min(polar_angle))\n",
    "hues = polar_angle  # Hue corresponds to normalized values\n",
    "saturation = 1.0  # Full saturation\n",
    "value = 1.0  # Full brightness\n",
    "polar_angle = np.stack([hues, np.full_like(hues, saturation), np.full_like(hues, value)], axis=1) # Combine to create HSV colors\n",
    "polar_angle = hsv_to_rgb(polar_angle) # Convert HSV to RGB\n",
    "\n",
    "eccentricity = (eccentricity - np.min(eccentricity)) / (np.max(eccentricity) - np.min(eccentricity))\n",
    "hues = eccentricity  # Hue corresponds to normalized values\n",
    "saturation = 1.0  # Full saturation\n",
    "value = 1.0  # Full brightness\n",
    "eccentricity = np.stack([hues, np.full_like(hues, saturation), np.full_like(hues, value)], axis=1) # Combine to create HSV colors\n",
    "eccentricity = hsv_to_rgb(eccentricity) # Convert HSV to RGB\n",
    "\n",
    "# visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(3, 6))\n",
    "if layer == \"layer41\": s = 0.1\n",
    "elif layer == \"layer31\": s = 0.05\n",
    "axes[0].scatter(positions[:, 0], positions[:, 1], c=polar_angle, s=s)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_title(\"Polar angle\", fontsize=22)\n",
    "for spine in axes[0].spines.values(): spine.set_visible(False)  # Remove outer black box\n",
    "axes[1].scatter(positions[:, 0], positions[:, 1], c=eccentricity, s=s)\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "axes[1].set_title(\"Eccentricity\", fontsize=22)\n",
    "for spine in axes[1].spines.values(): spine.set_visible(False)  # Remove outer black box\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "if layer == \"layer41\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_theta_r.png\", dpi=1000)\n",
    "elif layer == \"layer31\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_theta_r.png\", dpi=1000)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature dispersity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/sxy3f69j5_s5tn7m8cxwrgvw0000gn/T/ipykernel_57551/2012190994.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  FD_all[i] = FD[depth_index]\n"
     ]
    }
   ],
   "source": [
    "# feature dispersity map visualization\n",
    "layer = \"layer41\"\n",
    "if layer == \"layer41\":\n",
    "    positions = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANNfinal_positions/layer4.1.npz\")[\"coordinates\"] # (25088, 2)\n",
    "    FD = scipy.io.loadmat(\"/Users/dunhan/Desktop/topoV4/som/TDANN_dispersity/layer41_corrected6/FD.mat\")[\"TRsp\"]\n",
    "    num_units = 25088\n",
    "elif layer == \"layer31\":\n",
    "    positions = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANNfinal_positions/layer3.1.npz\")[\"coordinates\"] # (50176, 2)\n",
    "    FD = scipy.io.loadmat(\"/Users/dunhan/Desktop/topoV4/som/TDANN_dispersity/layer31_corrected6/FD.mat\")[\"TRsp\"]\n",
    "    num_units = 50176\n",
    "FD_all = np.zeros((num_units))\n",
    "for i in range(num_units):\n",
    "    if layer == \"layer41\": # 25088 = 512 * 7 * 7\n",
    "        depth_index = i // (7 * 7)        # Get index along the first dimension (512)\n",
    "        row_col_index = i % (7 * 7)       # Remaining index within the 7x7 matrix\n",
    "        FD_all[i] = FD[depth_index]\n",
    "    elif layer == \"layer31\": # 50176 = 256 * 14 * 14\n",
    "        depth_index = i // (14 * 14)\n",
    "        row_col_index = i % (14 * 14)\n",
    "        FD_all[i] = FD[depth_index]\n",
    "# FD_all_hist = FD_all.copy()\n",
    "grid_num = 60\n",
    "FD_map = np.zeros((grid_num, grid_num))\n",
    "cortical_size = max(positions[:, 0]) - min(positions[:, 0]) # define the length of the 2D plane\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=True):\n",
    "    for j in range(grid_num):\n",
    "        # first find all units in this current grid\n",
    "        xmin_cortex = cortical_size / grid_num * i\n",
    "        xmax_cortex = cortical_size / grid_num * (i + 1)\n",
    "        ymin_cortex = cortical_size / grid_num * j\n",
    "        ymax_cortex = cortical_size / grid_num * (j + 1)\n",
    "        # find all units in this current grid\n",
    "        units_within_grid_indeices = np.where((positions[:, 0] >= xmin_cortex) & (positions[:, 0] < xmax_cortex) & (positions[:, 1] >= ymin_cortex) & (positions[:, 1] < ymax_cortex))[0]\n",
    "        if len(units_within_grid_indeices) > 0:\n",
    "            FD_map[i, j] = np.mean(FD_all[units_within_grid_indeices])\n",
    "FD_all = (FD_all - np.min(FD_all)) / (np.max(FD_all) - np.min(FD_all))\n",
    "hues = FD_all  # Hue corresponds to normalized values\n",
    "saturation = 1.0  # Full saturation\n",
    "value = 1.0  # Full brightness\n",
    "FD_all = np.stack([hues, np.full_like(hues, saturation), np.full_like(hues, value)], axis=1) # Combine to create HSV colors\n",
    "FD_all = hsv_to_rgb(FD_all) # Convert HSV to RGB\n",
    "\n",
    "# visualization\n",
    "\"\"\"\n",
    "axes[1].hist(FD_all_hist, bins=10, color='gray')\n",
    "axes[1].set_title(\"FD distribution\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Counts\", fontsize=16)\n",
    "axes[1].set_yticks([]) # erase y-axis ticks\n",
    "axes[1].set_xticks([])\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(2, 1, figsize=(3, 6))\n",
    "if layer == \"layer41\": s = 0.1\n",
    "elif layer == \"layer31\": s = 0.05\n",
    "axes[0].scatter(positions[:, 0], positions[:, 1], c=FD_all, s=s)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_title(\"FD raw\", fontsize=20)\n",
    "for spine in axes[0].spines.values(): spine.set_visible(False)  # Remove outer black box\n",
    "im = axes[1].imshow(FD_map)\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "axes[1].set_title(\"FD map\", fontsize=20)\n",
    "cbar = fig.colorbar(im, ax=axes[1], orientation='vertical', shrink=0.8)\n",
    "cbar.set_label(\"FD Map Scale\")  # Optional label for colorbar\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "if layer == \"layer41\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN41_FD.png\", dpi=1000)\n",
    "elif layer == \"layer31\":\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_FD.png\", dpi=1000)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topoV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
