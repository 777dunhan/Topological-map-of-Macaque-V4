{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 digital twin image preference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "map initialization...: 100%|██████████| 128/128 [01:14<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the top-9 images of each grid in the V4 digital twin\n",
    "features = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/PRsp.npy\")\n",
    "features = np.transpose(features, (2, 1, 0)) # (128, 128, 50000)\n",
    "features = np.swapaxes(features, 0, 1)\n",
    "grid_num = int(features.shape[0])\n",
    "roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # 3048 roi voxels\n",
    "# define the path to the folder containing all images\n",
    "folder_path = \"/Users/dunhan/Desktop/topoV4/50K_Imgset/\"\n",
    "# define the size of a single image\n",
    "img_size = 30 # 4\n",
    "line_width = 5 # 1\n",
    "top_img_num = 9\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width,\n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "grid_top_images = np.zeros((grid_num, grid_num, top_img_num)) # store the top 9 images of each grid\n",
    "# fill the map with the images\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=False):\n",
    "    for j in range(grid_num):\n",
    "            if roi[i, j] == 1:\n",
    "                # 1-indexed image names\n",
    "                image_label = np.arange(50000) + 1 # or \"labels + 1\" if features were selected from the top-3 responsive images\n",
    "                # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "                _, image_label = zip(*sorted(zip(features[i, j, :],image_label)))\n",
    "                # take the top nine images with largest mean response\n",
    "                image_label = np.flip(image_label[-top_img_num:])\n",
    "                # store the 0-indexed 9 imgs of each grid\n",
    "                grid_top_images[i, j, :] = (image_label - 1).astype(int)\n",
    "\n",
    "                # locate the top left corner of the current grid in the map\n",
    "                x = i * (img_size*3 + line_width) + line_width\n",
    "                y = j * (img_size*3 + line_width) + line_width\n",
    "                \n",
    "                # fill the map's current grid with the selected nine images\n",
    "                for row in range(3):\n",
    "                    for col in range(3):    \n",
    "                        # load the image\n",
    "                        path = folder_path + str(int(image_label[row*3+col])) + \".bmp\" # the image name is 1-indexed\n",
    "                        img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "                        # put the image onto the map\n",
    "                        map[x + row * img_size : x + (row + 1) * img_size, \n",
    "                            y + col * img_size : y + (col + 1) * img_size, \n",
    "                            :] = img\n",
    "            else:\n",
    "                # fill the map's current grid with pure white color\n",
    "                x = i * (img_size*3 + line_width)\n",
    "                y = j * (img_size*3 + line_width)\n",
    "                map[x : x + img_size*3 + line_width*2, y : y + img_size*3 + line_width*2, :] = 1.0\n",
    "map = np.fliplr(np.flipud(map)) # top-bottom flip and then left-right flip\n",
    "size = (img_size*3 + line_width)\n",
    "map = map[38*size:114*size, 38*size:105*size, :] # only keep the roi part\n",
    "map_save_path = \"/Users/dunhan/Desktop/topoV4/som/Figures/V4_DT_full.bmp\"\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/rsptop_0index\", grid_top_images)\n",
    "matplotlib.image.imsave(map_save_path, map)\n",
    "del features, map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of RSOM training from V4 digital twin neuronal columns' tuning curves + estimated retinotopic positions\n",
    "# visualize the V4 data ROI shape\n",
    "roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "roi = np.flip(roi)\n",
    "roi = roi[37:115, 37:106]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "cmap = colors.ListedColormap(['white', 'lightyellow'])  # 0 for white, 1 for lightyellow\n",
    "ax.imshow(roi, cmap=cmap, interpolation='none')\n",
    "roi_grid = np.ma.masked_where(roi == 0, roi) # Create a masked array to only apply grid where roi is 1\n",
    "# Add grid lines only for the region of interest\n",
    "for i in range(roi.shape[0]):\n",
    "    for j in range(roi.shape[1]):\n",
    "        if roi[i, j] == 1:  # Only show grid for ROI entries with value 1\n",
    "            ax.plot([j-0.5, j+0.5], [i-0.5, i-0.5], color='black', linestyle='--', linewidth=0.5)  # Top line\n",
    "            ax.plot([j-0.5, j+0.5], [i+0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Bottom line\n",
    "            ax.plot([j-0.5, j-0.5], [i-0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Left line\n",
    "            ax.plot([j+0.5, j+0.5], [i-0.5, i+0.5], color='black', linestyle='--', linewidth=0.5)  # Right line\n",
    "# Add contour lines for the region of interest with a 3D effect (using multiple levels and shadowing)\n",
    "contour = ax.contour(roi, levels=[0.5], colors='black', linewidths=2, alpha=0.9)\n",
    "# Adding additional contour for 3D effect (shadow)\n",
    "ax.contour(roi, levels=[0.5], colors='gray', linewidths=6, alpha=0.75, linestyles='solid')\n",
    "# Remove axis labels and ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Remove the axis box\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(\"/Users/dunhan/Desktop/topoV4/som/Figures/ROI.png\", dpi=1000)\n",
    "plt.close()\n",
    "\n",
    "# Create a 60 by 60 grid to visualize the SOM map\n",
    "rows, cols = 60, 60\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(4, 4))  # Adjust figsize for higher resolution\n",
    "# Plot the grid\n",
    "for x in range(rows + 1):\n",
    "    ax.plot([x, x], [0, cols], color='black', linewidth=0.5)\n",
    "for y in range(cols + 1):\n",
    "    ax.plot([0, rows], [y, y], color='black', linewidth=0.5)\n",
    "# Set the aspect of the plot to be equal\n",
    "ax.set_aspect('equal')\n",
    "# Set limits to match grid size\n",
    "ax.set_xlim(0, rows)\n",
    "ax.set_ylim(0, cols)\n",
    "# Turn off axes ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Save as high resolution\n",
    "plt.savefig('/Users/dunhan/Desktop/grids.png', dpi=3000)  # Save the image in high resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSOM image preference map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"som16e_250tr_05t\" # and \"som16e\" for the SOM\n",
    "features = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/\" + name + \"/weights.npy\") # (60, 60, 50000(+))\n",
    "if features.shape[2] > 50000:\n",
    "    features = features[:, :, :-int(features.shape[2] - 50000)] # remove positional information from the data\n",
    "    assert features.shape[2] == 50000\n",
    "\n",
    "# define the path to the folder containing all images\n",
    "folder_path = \"/Users/dunhan/Desktop/topoV4/50K_Imgset/\"\n",
    "# define the size of a single image\n",
    "img_size = 30\n",
    "line_width = 5\n",
    "# create a blank map of black color (R=0, G=0, B=0)\n",
    "map = np.zeros((grid_num * (img_size*3 + line_width) + line_width,\n",
    "                grid_num * (img_size*3 + line_width) + line_width, \n",
    "                3))\n",
    "grid_top_images = np.zeros((grid_num, grid_num, top_img_num)) # store the top 9 images of each grid\n",
    "# fill the map with the images\n",
    "for i in tqdm(range(grid_num), desc=\"map initialization...\", disable=False):\n",
    "    for j in range(grid_num):\n",
    "            if roi[i, j] == 1:\n",
    "                # 1-indexed image names\n",
    "                image_label = np.arange(50000) + 1 # or \"labels + 1\" if features were selected from the top-3 responsive images\n",
    "                # sort the mean responses (from small to large) and the image_label according to the order of mean responses\n",
    "                _, image_label = zip(*sorted(zip(features[i, j, :],image_label)))\n",
    "                # take the top nine images with largest mean response\n",
    "                image_label = np.flip(image_label[-top_img_num:])\n",
    "                # store the 0-indexed 9 imgs of each grid\n",
    "                grid_top_images[i, j, :] = (image_label - 1).astype(int)\n",
    "\n",
    "                # locate the top left corner of the current grid in the map\n",
    "                x = i * (img_size*3 + line_width) + line_width\n",
    "                y = j * (img_size*3 + line_width) + line_width\n",
    "                \n",
    "                # fill the map's current grid with the selected nine images\n",
    "                for row in range(3):\n",
    "                    for col in range(3):\n",
    "                                \n",
    "                        # load the image\n",
    "                        path = folder_path + str(int(image_label[row*3+col])) + \".bmp\" # the image name is 1-indexed\n",
    "                        img = np.array(Image.open(path))[20:80, 20:80, :] # obtain the non-blurred central part of the image\n",
    "                        img = resize(img, (img_size, img_size, 3), anti_aliasing=True) # resize the image\n",
    "\n",
    "                        # put the image onto the map\n",
    "                        map[x + row * img_size : x + (row + 1) * img_size, \n",
    "                            y + col * img_size : y + (col + 1) * img_size, \n",
    "                            :] = img\n",
    "\n",
    "map_save_path = \"/Users/dunhan/Desktop/topoV4/som/weight_as_units/\" + name + \"/weights.bmp\"\n",
    "np.save(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/\" + name + \"/rsptop_0index\", grid_top_images)\n",
    "matplotlib.image.imsave(map_save_path, map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning curve shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3048)\n",
      "(50000, 3048)\n",
      "V4 half: 842.0524934383202 1297.4226355648088\n",
      "V4 and RSOM tuning curve correlation: 0.996\n",
      "V4_RSOM half 1157.6261111111112 1806.055900970211\n"
     ]
    }
   ],
   "source": [
    "# tuning curve comparison figure\n",
    "# Compare the tuning curves of V4 digital twin benchmark and the learned SOM\n",
    "# Load the V4 digital twin responses to 50k images\n",
    "response = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/Prsp.npy\")\n",
    "roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # (128, 128) <class 'numpy.ndarray'>\n",
    "v4_benchmark = response[:, roi == 1] # (50000, 128, 128) into (50000, 3048)\n",
    "print(v4_benchmark.shape) # (50000, 3048)\n",
    "v4_benchmark = np.sort(v4_benchmark, axis=0)[::-1]  # Sort each column along rows (flip for descending order)\n",
    "print(v4_benchmark.shape) # (50000, 3048)\n",
    "v4_mean = np.mean(v4_benchmark, axis=1) # mean tuning curve\n",
    "v4_std = np.std(v4_benchmark, axis=1) # tuning curve std\n",
    "index = []\n",
    "for i in range(v4_benchmark.shape[1]):\n",
    "    assert len(v4_benchmark[:, i]) == 50000\n",
    "    half = (np.max(v4_benchmark[:, i]) - np.min(v4_benchmark[:, i])) / 2\n",
    "    for j in range(50000):\n",
    "        if v4_benchmark[j, i] <= half:\n",
    "            index.append(j)\n",
    "            break\n",
    "print(\"V4 half:\", np.mean(index), np.std(index))\n",
    "\n",
    "name_all = [\"som16e_250tr_05t\"]\n",
    "# name_all = [\"som16e_250tr_1020\"]\n",
    "for name in name_all:\n",
    "    rsp = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/\" + name + \"/weights.npy\")\n",
    "    if rsp.shape[2] > 50000: rsp = rsp[:, :, :-int(rsp.shape[2] - 50000)] # now rsp / som weights has shape (60, 60, 50000)\n",
    "    rsp = rsp.reshape(-1, rsp.shape[2]) # (3600, 50000)\n",
    "    rsp = np.sort(rsp.T, axis=0)[::-1]  # Sort each column along rows (flip for descending order), (50000, 3600)\n",
    "    rsp_mean = np.mean(rsp, axis=1) # mean tuning curve\n",
    "    rsp_std = np.std(rsp, axis=1) # tuning curve std\n",
    "\n",
    "    # normalize every tuning curve\n",
    "    index = []\n",
    "    for i in range(rsp.shape[1]):\n",
    "        assert len(rsp[:, i]) == 50000\n",
    "        half = (np.max(rsp[:, i]) - np.min(rsp[:, i])) / 2\n",
    "        for j in range(50000):\n",
    "            if rsp[j, i] <= half:\n",
    "                index.append(j)\n",
    "                break\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    print(\"V4 and RSOM tuning curve correlation: {:.3f}\".format(pearsonr(np.concatenate((v4_mean, v4_std)), np.concatenate((rsp_mean, rsp_std)))[0]))\n",
    "    axes[0].plot(v4_mean, color='black')\n",
    "    axes[0].fill_between(range(len(v4_mean)), v4_mean - v4_std, v4_mean + v4_std, color='black', alpha=0.3)\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_xlabel('50K imgs', fontsize=16)\n",
    "    axes[0].set_ylabel('response', fontsize=16)\n",
    "    axes[0].set_title('V4', fontsize=18)\n",
    "    axes[1].plot(rsp_mean, color='gray')\n",
    "    axes[1].fill_between(range(len(rsp_mean)), rsp_mean - rsp_std, rsp_mean + rsp_std, color='gray', alpha=0.3)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_xlabel('50K imgs', fontsize=16)\n",
    "    # axes[1].set_ylabel('response', fontsize=18)\n",
    "    axes[1].set_title(\"RSOM\", fontsize=18)\n",
    "    fig = plt.gcf()\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    # fig.savefig(\"/Users/dunhan/Desktop/topoV4/som/Figures/tunings.png\", dpi=100)\n",
    "    fig.savefig(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/\" + name + \"/tunings.png\", dpi=1000)\n",
    "    del rsp, rsp_mean, rsp_std\n",
    "print(\"V4_RSOM half\", np.mean(index), np.std(index))\n",
    "del v4_benchmark, v4_mean, v4_std, name_all, name\n",
    "\n",
    "# V4 half: 842.0524934383202 1297.4226355648088\n",
    "# V4 and RSOM tuning curve correlation: 0.996\n",
    "# V4_RSOM half 1157.6261111111112 1806.055900970211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise columns / grids tuning correlation as a function of map distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pearson correlation of cordis function between V4 and V4_RSOM: 0.821\n",
      "PearsonRResult(statistic=0.9546374024653328, pvalue=2.3195355350045804e-53)\n"
     ]
    }
   ],
   "source": [
    "# pairwise grid tuning curve coorelation as a function of exactly the map physical distance between them\n",
    "def cordis(rsp):\n",
    "    # check input response\n",
    "    if rsp.shape[1] == rsp.shape[2] == 128: # (50000, 128, 128) V4 benchmark\n",
    "        roi = np.load(\"/Users/dunhan/Desktop/topoV4/Tianye/Analysis/S4_preference_map/ROI.npy\").T # (128, 128)\n",
    "    else: roi = np.ones((60, 60)).astype(int) # artificial som map weight response\n",
    "    size = roi.shape[0]\n",
    "    assert size == roi.shape[1]\n",
    "    num_roi = int(np.sum(roi))\n",
    "    # response, roi data preparation\n",
    "    response = np.zeros((num_roi, 50000))\n",
    "    position = np.zeros((num_roi, 2))\n",
    "    voxel_index = 0\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if roi[i, j] == 1:\n",
    "                response[voxel_index, :] = rsp[:, i, j]\n",
    "                position[voxel_index, 0] = i\n",
    "                position[voxel_index, 1] = j\n",
    "                voxel_index += 1\n",
    "    assert voxel_index == num_roi\n",
    "    # calculate the correlation matrix\n",
    "    cordis_matrix = np.zeros((num_roi, num_roi, 2)) # 0th entry for correlation, 1st entry for pairwise map distance\n",
    "    for i in tqdm(range(num_roi), desc=\"calculating correlation matrix...\", disable=False):\n",
    "        for j in range(i, num_roi):\n",
    "            # correlation calculation\n",
    "            if i != j:\n",
    "                cordis_matrix[i, j, 0] = pearsonr(response[i, :], response[j, :])[0]\n",
    "                cordis_matrix[j, i, 0] = cordis_matrix[i, j, 0]\n",
    "            else: cordis_matrix[i, j, 0] = 1.0\n",
    "            # distance calculation\n",
    "            cordis_matrix[i, j, 1] = np.sqrt((position[i, 0] - position[j, 0]) ** 2 + (position[i, 1] - position[j, 1]) ** 2)\n",
    "            cordis_matrix[j, i, 1] = cordis_matrix[i, j, 1]\n",
    "    return cordis_matrix\n",
    "# cordis_v4 = cordis(response)\n",
    "# np.save(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/cordis_v4.npy\", cordis_v4)\n",
    "# print(cordis_v4.shape)\n",
    "\n",
    "def cordis_avg(cordis_matrix, segment_num=100):\n",
    "    num_roi = cordis_matrix.shape[0]\n",
    "    assert num_roi == cordis_matrix.shape[1]\n",
    "    pd = cordis_matrix[:, :, 1] # distance (3048, 3048)\n",
    "    pc = cordis_matrix[:, :, 0] # correlation (3048, 3048)\n",
    "    dismax = np.max(pd) # maximum distance\n",
    "    dismin = np.min(pd) # minimum distance\n",
    "    segment_len = (dismax - dismin) / segment_num # length of one single segment\n",
    "    segments = np.zeros((num_roi, segment_num, 2)) # store the mean correlation and standard deviation of all correlation estimates within all samples of each segment\n",
    "    for i in tqdm(range(num_roi), desc=\"sorting...\", disable=True):\n",
    "        sorted_indices = np.argsort(pd[i, :]) # sort the distance from smallest to largest, get its indices\n",
    "        pd[i, :] = pd[i, sorted_indices] # distance matrix row vector sorted, from smallest to largest\n",
    "        pc[i, :] = pc[i, sorted_indices] # correlation matrix row vector sorted, from smallest to largest\n",
    "        for s in range(segment_num):\n",
    "            # indices of all entries within the current pairwise distance segment\n",
    "            segment_indices = np.where((pd[i, :] >= dismin + s * segment_len) & (pd[i, :] < dismin + (s + 1) * segment_len))[0]\n",
    "            if len(segment_indices) > 0:\n",
    "                selected_cor = pc[i, segment_indices] # current segment samples' correlation estimates\n",
    "                segments[i, s, 0] = np.mean(selected_cor) # average\n",
    "                segments[i, s, 1] = np.std(selected_cor) # standard deviation\n",
    "            else:\n",
    "                segments[i, s, 0] = -1\n",
    "                segments[i, s, 1] = -1\n",
    "    # compute the average of all ROIs' correlation estimates (mean and std) within each segment\n",
    "    mean_std_rois = np.zeros((segment_num, 3))\n",
    "    for i in range(num_roi):\n",
    "        for s in range(segment_num):\n",
    "            if segments[i, s, 0] != -1 and segments[i, s, 1] != -1:\n",
    "                mean_std_rois[s, 0] += segments[i, s, 0] # mean\n",
    "                mean_std_rois[s, 1] += segments[i, s, 1] # std\n",
    "                mean_std_rois[s, 2] += 1 # count\n",
    "    mean_std_rois[:, 0] /= mean_std_rois[:, 2] # average mean\n",
    "    mean_std_rois[:, 1] /= mean_std_rois[:, 2] # average std\n",
    "    mean_std_rois = mean_std_rois[:, :2] # discard the count\n",
    "    return mean_std_rois\n",
    "\n",
    "\n",
    "# V4 digital twin as benchmark\n",
    "segment_num = 100\n",
    "cordis_v4 = np.load(\"/Users/dunhan/Desktop/topoV4/som/V4_benchmark/cordis_v4_benchmark.npy\")\n",
    "mean_std_rois = cordis_avg(cordis_v4, segment_num) # V4 benchmark\n",
    "modes = [\"TDANN\", \"V4_RSOM\", \"V4_SOM\"]\n",
    "modes = [\"V4_RSOM\"]\n",
    "for mode in modes:\n",
    "    # RSOM\n",
    "    if mode == \"TDANN\":\n",
    "        # cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/som16e_250tr_TDANN41/cordis_resnet_rsom.npy\")\n",
    "        # cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/som16e_250_TDANNrfc/cordis_TDANN_rsom.npy\")\n",
    "        cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/ResNet/cordis_TDANN31.npy\")\n",
    "        cordis_rsom = np.nan_to_num(cordis_rsom, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    elif mode == \"V4_RSOM\":\n",
    "        cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/som16e_250tr_05t/cordis_V4_rsom.npy\")\n",
    "    elif mode == \"V4_SOM\":\n",
    "        cordis_rsom = np.load(\"/Users/dunhan/Desktop/topoV4/som/weight_as_units/som16e/cordis_V4_som.npy\")\n",
    "    mean_std_rois_rsom = cordis_avg(cordis_rsom, segment_num) # V4 RSOM or ResNet TDANN babynet RSOM\n",
    "    # visualization, as a comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].plot(mean_std_rois[:, 0], color='black')\n",
    "    axes[0].fill_between(np.arange((len(mean_std_rois[:, 0]))), \n",
    "                        mean_std_rois[:, 0]-mean_std_rois[:, 1], mean_std_rois[:, 0]+mean_std_rois[:, 1], color='black', alpha=0.3)\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_xlabel('Pairwise distance', fontsize=20)\n",
    "    axes[0].set_ylabel('Tuning correlation', fontsize=20)\n",
    "    axes[0].set_title(\"V4\", fontsize=28)\n",
    "    axes[1].plot(mean_std_rois_rsom[:, 0], color='gray')\n",
    "    axes[1].fill_between(np.arange((len(mean_std_rois_rsom[:, 0]))), \n",
    "                        mean_std_rois_rsom[:, 0]-mean_std_rois_rsom[:, 1], mean_std_rois_rsom[:, 0]+mean_std_rois_rsom[:, 1], color='gray', alpha=0.3)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_xlabel('Pairwise distance', fontsize=20)\n",
    "    # axes[1].set_ylabel('Tuning correlation', fontsize=20)\n",
    "    if mode == \"TDANN\":\n",
    "        axes[1].set_title(\"TDANN31\", fontsize=28) # ResNet RSOM\n",
    "        plt.tight_layout()\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(\"/Users/dunhan/Desktop/topoV4/ResNet/TDANN31_cor_dis.png\", dpi=1000)\n",
    "        print(\"pearson correlation of cordis function between V4 and TDANN31: {:.3f}\".format( # ResNet RSOM\n",
    "            pearsonr(np.concatenate((mean_std_rois[:, 0], mean_std_rois[:, 1])), np.concatenate((mean_std_rois_rsom[:, 0], mean_std_rois_rsom[:, 1])))[0]))\n",
    "        print(pearsonr(mean_std_rois[:, 0], mean_std_rois_rsom[:, 0]))\n",
    "    elif mode == \"V4_RSOM\":\n",
    "        axes[1].set_title(\"RSOM\", fontsize=28)\n",
    "        plt.tight_layout()\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(\"/Users/dunhan/Desktop/topoV4/som/Figures/cor_dis.png\", dpi=1000)\n",
    "        print(\"\\npearson correlation of cordis function between V4 and V4_RSOM: {:.3f}\".format(\n",
    "            pearsonr(np.concatenate((mean_std_rois[:, 0], mean_std_rois[:, 1])), np.concatenate((mean_std_rois_rsom[:, 0], mean_std_rois_rsom[:, 1])))[0]))\n",
    "        print(pearsonr(mean_std_rois[:, 0], mean_std_rois_rsom[:, 0]))\n",
    "    elif mode == \"V4_SOM\":\n",
    "        axes[1].set_title(\"SOM\", fontsize=28)\n",
    "        plt.tight_layout()\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(\"/Users/dunhan/Desktop/topoV4/som/Figures/cor_dis_som.png\", dpi=1000)\n",
    "        print(\"\\npearson correlation of cordis function between V4 and V4_SOM: {:.3f}\".format(\n",
    "            pearsonr(np.concatenate((mean_std_rois[:, 0], mean_std_rois[:, 1])), np.concatenate((mean_std_rois_rsom[:, 0], mean_std_rois_rsom[:, 1])))[0]))\n",
    "        print(pearsonr(mean_std_rois[:, 0], mean_std_rois_rsom[:, 0]))\n",
    "    plt.close()\n",
    "\n",
    "# pearson correlation of cordis function between V4 and TDANN31: 0.838\n",
    "# PearsonRResult(statistic=0.8288380838226055, pvalue=1.8549385524249295e-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/Users/dunhan/Desktop/Picture4.png\")\n",
    "width, height = image.size\n",
    "resized_image = image.resize((int(np.round(width/4)), int(np.round(height/4))), Image.Resampling.LANCZOS)\n",
    "resized_image.save(\"/Users/dunhan/Desktop/Fig4.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topoV4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
